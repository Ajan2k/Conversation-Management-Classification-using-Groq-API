{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 1**"
      ],
      "metadata": {
        "id": "99C2T4BCiOm8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eoxKTeXfLzR",
        "outputId": "204160a4-ee6a-49ea-ebac-b43b53422d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.108.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (4.25.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema) (0.27.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# Colab: first cell\n",
        "!pip install --upgrade openai jsonschema\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Prompt (no plain text in notebook)\n",
        "GROQ_API_KEY = getpass(\"Enter your GROQ API key (will not be shown): \").strip()\n",
        "os.environ['GROQ_API_KEY'] = GROQ_API_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ0l63O-fhyI",
        "outputId": "c898d4ce-63f3-48db-bed7-777b25a5b5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GROQ API key (will not be shown): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
        "    base_url=\"https://api.groq.com/openai/v1\"   # required for Groq\n",
        ")\n",
        "# Note: choose a Groq model that supports tool/function use (see Groq docs).\n"
      ],
      "metadata": {
        "id": "sz8Ih1fGfkcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "import json\n",
        "\n",
        "# Each message: {\"role\": \"system\"|\"user\"|\"assistant\", \"content\": \"...\"}\n",
        "\n",
        "def add_message(history: List[Dict], role: str, content: str):\n",
        "    history.append({\"role\": role, \"content\": content})\n",
        "    return history\n",
        "\n",
        "def truncate_by_turns(history: List[Dict], n: int, keep_system=True):\n",
        "    # Keep system message (if any) and last n messages (user+assistant)\n",
        "    system = [m for m in history if m[\"role\"] == \"system\"]\n",
        "    others = [m for m in history if m[\"role\"] != \"system\"]\n",
        "    truncated = others[-n:] if n < len(others) else others\n",
        "    return (system + truncated) if keep_system else truncated\n",
        "\n",
        "def truncate_by_length(history: List[Dict], max_chars: int, keep_system=True):\n",
        "    # Keep the most recent messages until total length <= max_chars\n",
        "    system = [m for m in history if m[\"role\"] == \"system\"]\n",
        "    others = [m for m in history if m[\"role\"] != \"system\"]\n",
        "    total = 0\n",
        "    kept = []\n",
        "    for m in reversed(others):\n",
        "        total += len(m[\"content\"])\n",
        "        if total > max_chars:\n",
        "            break\n",
        "        kept.append(m)\n",
        "    kept = list(reversed(kept))\n",
        "    return (system + kept) if keep_system else kept\n"
      ],
      "metadata": {
        "id": "Fb6cY_etfmeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_periodic_summarize(history, client, run_counter, k=3, keep_recent_n=2):\n",
        "    \"\"\"\n",
        "    After every k runs, create a summary and replace older messages with a single summary message.\n",
        "    keep_recent_n: keep last n original user/assistant messages AFTER the summary (so recent context is preserved)\n",
        "    \"\"\"\n",
        "    if run_counter % k != 0:\n",
        "        return history, None\n",
        "\n",
        "    summary_text = summarize_history_with_model(client, history)\n",
        "    # construct new history: keep system (if present), add summary-as-system, then keep last n messages\n",
        "    system_msgs = [m for m in history if m[\"role\"] == \"system\"]\n",
        "    others = [m for m in history if m[\"role\"] != \"system\"]\n",
        "    recent = others[-keep_recent_n:] if keep_recent_n > 0 else []\n",
        "    new_history = system_msgs + [{\"role\":\"system\",\"content\":f\"[SUMMARY]\\n{summary_text}\"}] + recent\n",
        "    return new_history, summary_text\n"
      ],
      "metadata": {
        "id": "jAhh8fHDfriD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_history_with_model(client, history, model=\"llama-3.3-70b-versatile\", max_tokens=400):\n",
        "    # join history into a single block for summarization\n",
        "    convo = \"\\n\".join([f\"{m['role'].upper()}: {m['content']}\" for m in history])\n",
        "    system = \"You are a helpful assistant that produces SHORT, structured summaries (3-5 lines). Focus on facts and decisions.\"\n",
        "    user_prompt = f\"Summarize the conversation below into a short paragraph with key points and action items:\\n\\n{convo}\"\n",
        "\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":system},\n",
        "            {\"role\":\"user\",\"content\":user_prompt}\n",
        "        ],\n",
        "        temperature=0.2,\n",
        "        max_tokens=max_tokens\n",
        "    )\n",
        "    summary = resp.choices[0].message.content   # typical response structure\n",
        "    return summary.strip()\n"
      ],
      "metadata": {
        "id": "m_CpVjW2fpKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "RwP4WUyFiV1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "contact_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"email\": {\"type\": \"string\", \"format\": \"email\"},\n",
        "        \"phone\": {\"type\": \"string\"},\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"maximum\": 130}\n",
        "    },\n",
        "    \"required\": [\"name\", \"email\"],   # minimal requirement; adjust as assignment expects\n",
        "    \"additionalProperties\": False\n",
        "}\n"
      ],
      "metadata": {
        "id": "-U8LQpQ6gpiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo samples\n",
        "samples = [\n",
        "    {\"role\":\"user\",\"content\":\"Hi, I'm Alice. My email is alice@example.com. I'm 29 and live in Pune.\"},\n",
        "    {\"role\":\"assistant\",\"content\":\"Thanks Alice — I can help. Do you want to sign up?\"},\n",
        "    {\"role\":\"user\",\"content\":\"Yes, and also please note my phone: +91-98765-43210.\"},\n",
        "    # ... more turns to simulate a long conversation\n",
        "]\n",
        "\n",
        "history = []\n",
        "run_counter = 0\n",
        "K = 3  # summarize after each 3 runs\n",
        "\n",
        "for msg in samples:\n",
        "    add_message(history, msg[\"role\"], msg[\"content\"])\n",
        "    run_counter += 1\n",
        "    history, summary = maybe_periodic_summarize(history, client, run_counter, k=K, keep_recent_n=1)\n",
        "    print(f\"--- After run {run_counter} ---\")\n",
        "    if summary:\n",
        "        print(\"SUMMARY (stored):\", summary)\n",
        "    print(\"History length:\", len(history))\n",
        "    # Show truncation examples\n",
        "    print(\"Truncate by turns (last 2):\", truncate_by_turns(history, 2))\n",
        "    print(\"Truncate by length (max 200 chars):\", truncate_by_length(history, 200))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyvEKq_JfuIa",
        "outputId": "9cc3c758-56de-4bc1-fc45-5546f3aa6601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- After run 1 ---\n",
            "History length: 1\n",
            "Truncate by turns (last 2): [{'role': 'user', 'content': \"Hi, I'm Alice. My email is alice@example.com. I'm 29 and live in Pune.\"}]\n",
            "Truncate by length (max 200 chars): [{'role': 'user', 'content': \"Hi, I'm Alice. My email is alice@example.com. I'm 29 and live in Pune.\"}]\n",
            "\n",
            "\n",
            "--- After run 2 ---\n",
            "History length: 2\n",
            "Truncate by turns (last 2): [{'role': 'user', 'content': \"Hi, I'm Alice. My email is alice@example.com. I'm 29 and live in Pune.\"}, {'role': 'assistant', 'content': 'Thanks Alice — I can help. Do you want to sign up?'}]\n",
            "Truncate by length (max 200 chars): [{'role': 'user', 'content': \"Hi, I'm Alice. My email is alice@example.com. I'm 29 and live in Pune.\"}, {'role': 'assistant', 'content': 'Thanks Alice — I can help. Do you want to sign up?'}]\n",
            "\n",
            "\n",
            "--- After run 3 ---\n",
            "SUMMARY (stored): Key points: Alice introduced herself, sharing her email and age. \n",
            "Action items: Sign up Alice with email alice@example.com and phone +91-98765-43210. \n",
            "Next steps: Complete the sign-up process for Alice.\n",
            "History length: 2\n",
            "Truncate by turns (last 2): [{'role': 'system', 'content': '[SUMMARY]\\nKey points: Alice introduced herself, sharing her email and age. \\nAction items: Sign up Alice with email alice@example.com and phone +91-98765-43210. \\nNext steps: Complete the sign-up process for Alice.'}, {'role': 'user', 'content': 'Yes, and also please note my phone: +91-98765-43210.'}]\n",
            "Truncate by length (max 200 chars): [{'role': 'system', 'content': '[SUMMARY]\\nKey points: Alice introduced herself, sharing her email and age. \\nAction items: Sign up Alice with email alice@example.com and phone +91-98765-43210. \\nNext steps: Complete the sign-up process for Alice.'}, {'role': 'user', 'content': 'Yes, and also please note my phone: +91-98765-43210.'}]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "functions = [\n",
        "    {\n",
        "        \"name\": \"extract_contact_info\",\n",
        "        \"description\": \"Extract contact info: name, email, phone, location, age from the chat text\",\n",
        "        \"parameters\": contact_schema\n",
        "    }\n",
        "]\n",
        "\n",
        "def run_extraction(client, text, model=\"llama-3.3-70b-versatile\"):\n",
        "    resp = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":\"You are a JSON extractor. Respond only with the JSON matching the schema when possible.\"},\n",
        "            {\"role\":\"user\",\"content\": f\"Extract contact details from the following message:\\n\\n{text}\"}\n",
        "        ],\n",
        "        functions=functions,\n",
        "        function_call={\"name\":\"extract_contact_info\"}  # force function-like output\n",
        "    )\n",
        "    # Inspect the response to find the function call args\n",
        "    choice = resp.choices[0].message\n",
        "    # Different SDKs represent this slightly differently; try both:\n",
        "    function_call = None\n",
        "    if hasattr(choice, \"function_call\"):\n",
        "        function_call = choice.function_call\n",
        "    else:\n",
        "        function_call = choice.get(\"function_call\") if isinstance(choice, dict) else None\n",
        "\n",
        "    if function_call:\n",
        "        args_text = function_call[\"arguments\"] if isinstance(function_call, dict) else function_call.arguments\n",
        "        try:\n",
        "            parsed = json.loads(args_text)\n",
        "        except Exception as e:\n",
        "            parsed = None\n",
        "        return parsed, resp\n",
        "    else:\n",
        "        # fallback: parse content as JSON\n",
        "        try:\n",
        "            parsed = json.loads(choice.content)\n",
        "        except Exception:\n",
        "            parsed = None\n",
        "        return parsed, resp\n"
      ],
      "metadata": {
        "id": "vyYhI0JpgtKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jsonschema import validate, ValidationError\n",
        "\n",
        "def validate_extracted(parsed):\n",
        "    try:\n",
        "        validate(instance=parsed, schema=contact_schema)\n",
        "        return True, None\n",
        "    except ValidationError as e:\n",
        "        return False, str(e)\n"
      ],
      "metadata": {
        "id": "XxhxbdYIgvoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_chats = [\n",
        "    \"Hello, I'm Rajesh Kumar. My email is rajesh.k@example.com. I'm 34 and live in Bangalore. Phone: +91 90000 11111.\",\n",
        "    \"Name: Priya Singh; Email: priya_s@hotmail.com; Age: 27; City: Mumbai; Contact: 9876543210\",\n",
        "    \"Hey! It's Sam. Reach me at sam@example.org. 22 y/o. Based in New Delhi.\"\n",
        "]\n",
        "\n",
        "for text in sample_chats:\n",
        "    parsed, resp = run_extraction(client, text)\n",
        "    ok, err = validate_extracted(parsed) if parsed else (False, \"parse failed\")\n",
        "    print(\"Input:\", text)\n",
        "    print(\"Parsed:\", parsed)\n",
        "    print(\"Validation OK:\", ok)\n",
        "    if not ok:\n",
        "        print(\"Validation Error:\", err)\n",
        "    print(\"---\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnqUWgkegxl4",
        "outputId": "594ec6a0-a9d7-474f-e40c-a2a4760d9a40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hello, I'm Rajesh Kumar. My email is rajesh.k@example.com. I'm 34 and live in Bangalore. Phone: +91 90000 11111.\n",
            "Parsed: {'age': 34, 'email': 'rajesh.k@example.com', 'location': 'Bangalore', 'name': 'Rajesh Kumar', 'phone': '+91 90000 11111'}\n",
            "Validation OK: True\n",
            "---\n",
            "Input: Name: Priya Singh; Email: priya_s@hotmail.com; Age: 27; City: Mumbai; Contact: 9876543210\n",
            "Parsed: {'age': 27, 'email': 'priya_s@hotmail.com', 'location': 'Mumbai', 'name': 'Priya Singh', 'phone': '9876543210'}\n",
            "Validation OK: True\n",
            "---\n",
            "Input: Hey! It's Sam. Reach me at sam@example.org. 22 y/o. Based in New Delhi.\n",
            "Parsed: {'age': 22, 'email': 'sam@example.org', 'location': 'New Delhi', 'name': 'Sam', 'phone': ''}\n",
            "Validation OK: True\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}